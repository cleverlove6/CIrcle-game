#！/user/bin/env python
# _*_ coding:utf-8 _*_

from pymongo import MongoClient

client = MongoClient()

db = client.test# 链接test的数据库，没有的就是直接创建的

my_set = db.set  # 使用set的集合，没有的话自动创建

my_set.insert({"name":"sdfs","age":14})  # 在已经存在的集合下面插入数据

-----------------------------------------------------------------------------------
#! /user/bin/env python
# _*_ encoding:utf-8 _*_
import time
import pandas as pd
import requests
from pymongo import MongoClient
client = MongoClient()
db = client.lagouxinxi
my_set = db.job


url = "https://www.lagou.com/jobs/positionAjax.json?city=%E5%8C%97%E4%BA%AC&district" \
      "=%E6%9C%9D%E9%98%B3%E5%8C%BA&needAddtionalResult=false "

def get_info(page):
    for i in range(page):

        payload = {
            "first": "false",
            "pn": "i",
            "kd": "python爬虫"
        }

        headers = {
            "Cookie": "ga=GA1.2.1404727440.1523635660; user_trace_token=20180414000738-c999d72f-3f34-11e8-b838-5254005c3644; LGUID=20180414000738-c999"
                      "dbeb-3f34-11e8-b838-5254005c3644; hasDeliver=0; showExpriedIndex=1; showExpriedCompanyHome=1; showExpriedMyPublish=1; index_location_city="
                      "%E5%8C%97%E4%BA%AC; WEBTJ-ID=20180415001714-162c4f244e48f-046064f3b53c82-3a614f0b-921600-162c4f244e5256; _gat=1; Hm_lvt_4233e74dff0ae5bd0a3d81c6ccf756e6=1523635660,1523722635; LGSID=20180415001713-4a9f3bc3-3fff-11e8-b880-5254005c3644; PRE_UTM=m_cf_cpt_baidu_pc; PRE_HOST=www.baidu.com; PRE_SITE=https%3A%2F%2Fwww.baidu.com%2Fs%3Fie%3Dutf-8%26f%3D8%26rsv_bp%3D0%26rsv_idx%3D1%26tn%3Dbaidu%26wd%3D%25E6%258B%2589%25E9%2592%25A9%25E7%25BD%2591%26rsv_pq%3D8aa9b6ba0002bbcc%26rsv_t%3D6ba8LMYkY4Zhor%252BK%252FluWzoGqTiHqL7rbrNyMJnpeFuVNUKYt4ITajHsv8zE%26rqlang%3Dcn%26rsv_enter%3D1%26rsv_sug3%3D12%26rsv_sug1%3D5%26rsv_sug7%3D100%26rsv_sug2%3D0%26inputT%3D546638%26rsv_sug4%3D550527%26rsv_sug%3D1; PRE_LAND=https%3A%2F%2Fwww.lagou.com%2Flp%2Fhtml%2Fcommon.html%3Futm_source%3Dm_cf_cpt_baidu_pc; _gid=GA1.2.618552378.1523722635; _putrc=19DD8FEB018CD4A3123F89F2B170EADC; JSESSIONID=ABAAABAAAGFABEF2756BDFF47DA2A4595174200D8E9A863; login=true; unick=%E6%9D%8E%E4%BF%8A%E5%B3%B0; gate_login_token=0ea72b9512e98488a1adccfc8e6108fb37beaeda7a97951f5381116337c0e358; TG-TRACK-CODE=index_navigation; SEARCH_ID=5286a122d3234ad3a000665c78ef2991; Hm_lpvt_4233e74dff0ae5bd0a3d81c6ccf756e6=1523722757; LGRID=20180415001924-98cdbeb4-3fff-11e8-854d-525400f775ce",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36",
            "Referer": "https://www.lagou.com/jobs/list_python%E7%88%AC%E8%99%AB?oquery=python&fromSearch=true&labelWords=relative&city=%E5%8C%97%E4%BA%AC&district=%E6%9C%9D%E9%98%B3%E5%8C%BA"

        }

        response = requests.post(url, data=payload, headers=headers)

        if response.status_code == 200:
            my_set.insert(response.json()["content"]["positionResult"]["result"])
        else:
            print("你的输入错误")

        print("正在爬取第" + str(i+1) + "页")
        time.sleep(1)


if __name__ == '__main__':
    get_info(27)

-------------------------------------------------------------------------------------------------------------------------------------
#! user/bin/env python
# _*_ coding:utf-8 _*_

import requests
import time

from fake_useragent import UserAgent
from pymongo import MongoClient

client = MongoClient()

db = client.kaihua

my_set = db.like

headers = {
            "Cookie":"_ga=GA1.2.1404727440.1523635660; user_trace_token=20180414000738-c999d72f-3f34-11e8-b838-5254005c3644; LGUID=20180414000738-c999dbeb-3f34-11e8-b838-5254005c3644; hasDeliver=0; showExpriedIndex=1; showExpriedCompanyHome=1; showExpriedMyPublish=1; index_location_city=%E5%8C%97%E4%BA%AC; WEBTJ-ID=20180415001714-162c4f244e48f-046064f3b53c82-3a614f0b-921600-162c4f244e5256; _gat=1; Hm_lvt_4233e74dff0ae5bd0a3d81c6ccf756e6=1523635660,1523722635; LGSID=20180415001713-4a9f3bc3-3fff-11e8-b880-5254005c3644; PRE_UTM=m_cf_cpt_baidu_pc; PRE_HOST=www.baidu.com; PRE_SITE=https%3A%2F%2Fwww.baidu.com%2Fs%3Fie%3Dutf-8%26f%3D8%26rsv_bp%3D0%26rsv_idx%3D1%26tn%3Dbaidu%26wd%3D%25E6%258B%2589%25E9%2592%25A9%25E7%25BD%2591%26rsv_pq%3D8aa9b6ba0002bbcc%26rsv_t%3D6ba8LMYkY4Zhor%252BK%252FluWzoGqTiHqL7rbrNyMJnpeFuVNUKYt4ITajHsv8zE%26rqlang%3Dcn%26rsv_enter%3D1%26rsv_sug3%3D12%26rsv_sug1%3D5%26rsv_sug7%3D100%26rsv_sug2%3D0%26inputT%3D546638%26rsv_sug4%3D550527%26rsv_sug%3D1; PRE_LAND=https%3A%2F%2Fwww.lagou.com%2Flp%2Fhtml%2Fcommon.html%3Futm_source%3Dm_cf_cpt_baidu_pc; _gid=GA1.2.618552378.1523722635; _putrc=19DD8FEB018CD4A3123F89F2B170EADC; JSESSIONID=ABAAABAAAGFABEF2756BDFF47DA2A4595174200D8E9A863; login=true; unick=%E6%9D%8E%E4%BF%8A%E5%B3%B0; gate_login_token=0ea72b9512e98488a1adccfc8e6108fb37beaeda7a97951f5381116337c0e358; TG-TRACK-CODE=index_navigation; SEARCH_ID=5286a122d3234ad3a000665c78ef2991; Hm_lpvt_4233e74dff0ae5bd0a3d81c6ccf756e6=1523722757; LGRID=20180415001924-98cdbeb4-3fff-11e8-854d-525400f775ce",
            "Referer":"https://www.lagou.com/jobs/list_python%E7%88%AC%E8%99%AB?oquery=python&fromSearch=true&labelWords=relative&city=%E5%8C%97%E4%BA%AC&district=%E6%9C%9D%E9%98%B3%E5%8C%BA",
            "User-Agent":"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36"
        }


def get_web_info(page,kd):

    for i in range(page):
        url = "https://www.lagou.com/jobs/positionAjax.json?city=%E5%8C%97%E4%BA%AC&district=%E6%9C%9D%E9%98%B3%E5%8C%BA&needAddtionalResult=false"
        payload = {
                "first": "false",
                "page": str(i),
                "kd": kd
        }

        ua = UserAgent()
        headers["User-Agent"] = ua.random

        response = requests.post(url, data=payload, headers=headers)

        if response.status_code == 200:

            job_json = response.json()["content"]["positionResult"]["result"]
            my_set.insert(job_json)
            # my_set.insert(response.json()["content"]["positionResult"]["result"])
        else:
            print("错误")

        print("正在打印第" + str(i + 1) + "页")
        time.sleep(1)


if __name__ == '__main__':
    get_web_info(27,"java")





